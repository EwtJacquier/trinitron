<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>CRT Webcam Viewer</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background: black;
      color: white;
      font-family: sans-serif;
      height: 100%;
      overflow: hidden;
    }

    #menu {
      position: absolute;
      top: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.8);
      padding: 15px;
      border-radius: 8px;
      z-index: 10;
    }

    select, button {
      margin: 5px 0;
      padding: 5px;
      width: 100%;
    }

    canvas {
      display: block;
      width: 100vw;
      height: 100vh;
      image-rendering: pixelated;
    }

    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      overflow: hidden;
    }

    #crt-overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;

      background:
        repeating-linear-gradient(
          to bottom,
          rgba(0, 0, 0, 0.15),
          rgba(0, 0, 0, 0.15) 1px,
          transparent 1px,
          transparent 3px
        );

      mix-blend-mode: multiply;
      z-index: 2;
      animation: flicker 0.15s infinite alternate;
    }

    @keyframes flicker {
      0%   { opacity: 0.93; }
      100% { opacity: 1; }
    }

    #fps {
      position: absolute;
      top: 10px;
      right: 10px;
      font-size: 14px;
      background: rgba(0,0,0,0.5);
      padding: 5px;
    }
  </style>
</head>
<body>

  <div id="menu">
    <label>Camera:
      <select id="cameraSelect"></select>
    </label><br>
    <label>Microphone:
      <select id="micSelect"></select>
    </label><br>
    <button id="startBtn">Start</button>
  </div>

  <video id="video" autoplay playsinline muted style="display:none;"></video>
  <audio id="audio" autoplay controls style="display:none;"></audio>
  <div id="container">
    <canvas id="canvas"></canvas>
    <div id="crt-overlay"></div>
  </div>
  <div id="fps">FPS: 0</div>

  <script>
    const cameraSelect = document.getElementById('cameraSelect');
    const micSelect = document.getElementById('micSelect');
    const startBtn = document.getElementById('startBtn');
    const menu = document.getElementById('menu');
    const video = document.getElementById('video');
    const audio = document.getElementById('audio');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const fpsDisplay = document.getElementById('fps');

    let videoStream;
    let audioStream;
    let lastTime = performance.now();
    let frames = 0;

    async function requestPermissionsAndListDevices() {
      try {
        const tempStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        await listDevices();
        tempStream.getTracks().forEach(t => t.stop());
      } catch (err) {
        alert("Permission denied or error accessing media: " + err.message);
        console.error(err);
      }
    }

    async function listDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();

      cameraSelect.innerHTML = '';
      micSelect.innerHTML = '';

      devices.forEach(device => {
        const option = document.createElement('option');
        option.value = device.deviceId;
        option.text = device.label || `${device.kind}`;

        if (device.kind === 'videoinput') {
          cameraSelect.appendChild(option);
        } else if (device.kind === 'audioinput') {
          micSelect.appendChild(option);
        }
      });
    }

    async function startStream() {
      const videoSource = cameraSelect.value;
      const audioSource = micSelect.value;

      const videoConstraints = {
        deviceId: videoSource ? { exact: videoSource } : undefined,
        frameRate: { ideal: 60, max: 60 },
        width: { ideal: 1920 },
        height: { ideal: 1080 }
      };

      const audioConstraints = {
        deviceId: audioSource ? { exact: audioSource } : undefined,
        autoGainControl: false,
        echoCancellation: false,
        googAutoGainControl: false,
        noiseSuppression: false
      };

      try {
        if (videoStream) videoStream.getTracks().forEach(t => t.stop());
        if (audioStream) audioStream.getTracks().forEach(t => t.stop());

        videoStream = await navigator.mediaDevices.getUserMedia({ video: videoConstraints });
        audioStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });

        video.srcObject = videoStream;
        audio.srcObject = audioStream;

        video.onloadedmetadata = () => {
          video.play();
          menu.style.display = 'none';
          startCRT();
        };
      } catch (err) {
        alert("Error starting media: " + err.message);
        console.error(err);
      }
    }

    function applyCRTEffect(videoElement, ctx, x, y, width, height) {
      const imageData = ctx.getImageData(x, y, width, height);
      const data = imageData.data;

      const brightness = 1.03;
      const hasNextCol = width - 1;

      for (let row = 0; row < height; row++) {
        const base = row * width * 4;
        const isScanline = (row & 1) === 0; // bitwise mod 2

        for (let col = 0; col < width; col++) {
          const i = base + col * 4;

          // Carrega valores RGB
          let r = data[i];
          let g = data[i + 1];
          let b = data[i + 2];

          // Blend horizontal
          if (col < hasNextCol) {
            const ni = i + 4;
            r = (r + data[ni]) >> 1;
            g = (g + data[ni + 1]) >> 1;
            b = (b + data[ni + 2]) >> 1;
          }

          // Aberração cromática (leve)
          r *= 1.1;
          g *= 1.05;
          b *= 0.95;

          // Scanline (escurece linhas pares)
          if (isScanline) {
            r *= 0.7;
            g *= 0.7;
            b *= 0.7;
          }

          // Brilho
          data[i]     = r * brightness > 255 ? 255 : r * brightness;
          data[i + 1] = g * brightness > 255 ? 255 : g * brightness;
          data[i + 2] = b * brightness > 255 ? 255 : b * brightness;
        }
      }

      ctx.putImageData(imageData, x, y);

      // Scanlines visuais extras (opcional, mas leve agora)
      ctx.fillStyle = 'rgba(0, 0, 0, 0.05)';
      for (let scanY = y; scanY < y + height; scanY += 2) {
        ctx.fillRect(x, scanY, width, 1);
      }
    }

    function applyPixelBlendEffect(ctx, x, y, width, height) {
      const imageData = ctx.getImageData(x, y, width, height);
      const src = imageData.data;

      // Novo buffer triplo horizontal
      const newWidth = width * 3;
      const newImageData = ctx.createImageData(newWidth, height);
      const dst = newImageData.data;

      for (let row = 0; row < height; row++) {
        for (let col = 0; col < width; col++) {
          const i = (row * width + col) * 4;

          // Pega cor atual
          const r = src[i];
          const g = src[i + 1];
          const b = src[i + 2];
          const a = src[i + 3];

          // Cor anterior
          const iPrev = (row * width + Math.max(0, col - 1)) * 4;
          const rPrev = src[iPrev];
          const gPrev = src[iPrev + 1];
          const bPrev = src[iPrev + 2];

          // Cor próxima
          const iNext = (row * width + Math.min(width - 1, col + 1)) * 4;
          const rNext = src[iNext];
          const gNext = src[iNext + 1];
          const bNext = src[iNext + 2];

          // Subpixel 1 (esquerda): blend com anterior
          const base1 = ((row * newWidth) + (col * 3)) * 4;
          dst[base1]     = (r + rPrev) >> 1;
          dst[base1 + 1] = (g + gPrev) >> 1;
          dst[base1 + 2] = (b + bPrev) >> 1;
          dst[base1 + 3] = a;

          // Subpixel 2 (centro): cor original
          const base2 = base1 + 4;
          dst[base2]     = r;
          dst[base2 + 1] = g;
          dst[base2 + 2] = b;
          dst[base2 + 3] = a;

          // Subpixel 3 (direita): blend com próximo
          const base3 = base2 + 4;
          dst[base3]     = (r + rNext) >> 1;
          dst[base3 + 1] = (g + gNext) >> 1;
          dst[base3 + 2] = (b + bNext) >> 1;
          dst[base3 + 3] = a;
        }
      }

      // Redimensiona o canvas virtualmente (sem mudar o tamanho real do canvas)
      ctx.clearRect(0, 0, width, height);
      ctx.putImageData(newImageData, 0, 0);
    }

    function startCRT() {
      function resizeCanvas() {
        canvas.width = 398;
        canvas.height = 224;
      }

      resizeCanvas();
      //window.addEventListener('resize', resizeCanvas);

      function drawFrame() {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        const videoAspect = video.videoWidth / video.videoHeight;
        const canvasAspect = canvas.width / canvas.height;

        let drawWidth, drawHeight, offsetX, offsetY;

        if (canvasAspect > videoAspect) {
          // canvas mais largo que o vídeo
          drawHeight = canvas.height;
          drawWidth = drawHeight * videoAspect;
          offsetX = (canvas.width - drawWidth) / 2;
          offsetY = 0;
        } else {
          // canvas mais alto que o vídeo
          drawWidth = canvas.width;
          drawHeight = drawWidth / videoAspect;
          offsetX = 0;
          offsetY = (canvas.height - drawHeight) / 2;
        }

        ctx.drawImage(video, offsetX, offsetY, drawWidth, drawHeight);

        //applyCRTEffect(video, ctx, offsetX, offsetY, drawWidth, drawHeight);
        applyPixelBlendEffect(ctx, offsetX, offsetY, drawWidth, drawHeight);
        
        frames++;
        const now = performance.now();
        if (now - lastTime >= 1000) {
          fpsDisplay.textContent = `FPS: ${frames}`;
          frames = 0;
          lastTime = now;
        }

        requestAnimationFrame(drawFrame);
      }

      requestAnimationFrame(drawFrame);
    }

    startBtn.addEventListener('click', startStream);
    requestPermissionsAndListDevices();
  </script>
</body>
</html>
