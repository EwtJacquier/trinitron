<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>CRT Webcam Viewer WebGL - Sem limitador de FPS</title>
  <style>
    html, body {
      margin: 0; padding: 0;
      background: black; color: white;
      height: 100%;
      overflow: hidden;
      font-family: sans-serif;
    }
    #canvas {
      filter: saturate(1.3) brightness(1.04);
    }
    #menu {
      position: absolute;
      top: 10px; left: 10px;
      background: rgba(0,0,0,0.8);
      padding: 15px;
      border-radius: 8px;
      z-index: 10;
    }
    select, button {
      margin: 5px 0;
      padding: 5px;
      width: 100%;
    }
    #container {
      position: relative;
      width: 100vw; height: 100vh;
      overflow: hidden;
    }
    #crt-overlay {
      background: url(/crt.png) no-repeat center center;
      background-size: 100% 150%;
      position: absolute;
      inset: 0;
      pointer-events: none;
      border-radius: 5%;
      box-shadow: inset 0 0 80px rgb(175 63 63 / 28%);
      mix-blend-mode: normal;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: auto;
      height: 95%;
      z-index: 2;
      animation: flicker 0.15s infinite alternate;
      aspect-ratio: 260/240;
    }
    @keyframes flicker {
      0%   { opacity: 0.5; }
      100% { opacity: 0.48; }
    }
    #fps {
      position: absolute;
      top: 10px;
      right: 10px;
      font-size: 14px;
      background: rgba(0,0,0,0.5);
      padding: 5px;
      z-index: 10;
    }
  </style>
</head>
<body>

<div id="menu">
  <label>Camera:
    <select id="cameraSelect"></select>
  </label><br>
  <label>Microphone:
    <select id="micSelect"></select>
  </label><br>
  <button id="startBtn">Start</button>
</div>

<video id="video" autoplay playsinline muted style="display:none;"></video>
<audio id="audio" autoplay controls style="display:none;"></audio>
<div id="container">
  <canvas id="canvas"></canvas>
  <div id="crt-overlay"></div>
</div>
<div id="fps">FPS: 0</div>

<script>
  const cameraSelect = document.getElementById('cameraSelect');
  const micSelect = document.getElementById('micSelect');
  const startBtn = document.getElementById('startBtn');
  const menu = document.getElementById('menu');
  const video = document.getElementById('video');
  const audio = document.getElementById('audio');
  const canvas = document.getElementById('canvas');
  const fpsDisplay = document.getElementById('fps');
  const overlay = document.getElementById('crt-overlay')

  let videoStream;
  let audioStream;
  let gl;
  let program;
  let positionBuffer;
  let texCoordBuffer;
  let texture;
  let lastTime = performance.now();
  let frames = 0;

  let videoAspect;

  const vsSource = `
    attribute vec2 a_position;
    attribute vec2 a_texCoord;
    varying vec2 v_texCoord;

    void main() {
      gl_Position = vec4(a_position, 0, 1);
      v_texCoord = a_texCoord;
    }
  `;

  const fsSource = `
    precision mediump float;
    varying vec2 v_texCoord;
    uniform sampler2D u_texture;

    void main() {
      vec4 color = texture2D(u_texture, v_texCoord);
      gl_FragColor = color;
    }
  `;

  function createShader(gl, type, source) {
    const shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
      console.error('Shader compile failed:', gl.getShaderInfoLog(shader));
      gl.deleteShader(shader);
      return null;
    }
    return shader;
  }

  function createProgram(gl, vsSource, fsSource) {
    const vertexShader = createShader(gl, gl.VERTEX_SHADER, vsSource);
    const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fsSource);
    const program = gl.createProgram();
    gl.attachShader(program, vertexShader);
    gl.attachShader(program, fragmentShader);
    gl.linkProgram(program);
    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
      console.error('Program link failed:', gl.getProgramInfoLog(program));
      gl.deleteProgram(program);
      return null;
    }
    return program;
  }

  async function requestPermissionsAndListDevices() {
    try {
      const tempStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      await listDevices();
      tempStream.getTracks().forEach(t => t.stop());
    } catch (err) {
      alert("Permission denied or error accessing media: " + err.message);
      console.error(err);
    }
  }

  async function listDevices() {
    const devices = await navigator.mediaDevices.enumerateDevices();
    cameraSelect.innerHTML = '';
    micSelect.innerHTML = '';

    devices.forEach(device => {
      const option = document.createElement('option');
      option.value = device.deviceId;
      option.text = device.label || `${device.kind}`;
      if (device.kind === 'videoinput') {
        cameraSelect.appendChild(option);
      } else if (device.kind === 'audioinput') {
        micSelect.appendChild(option);
      }
    });
  }

  async function startStream() {
    const videoSource = cameraSelect.value;
    const audioSource = micSelect.value;

    const videoConstraints = {
      deviceId: videoSource ? { exact: videoSource } : undefined,
      frameRate: { ideal: 60, max: 60 },
      width: { ideal: 1920 },
      height: { ideal: 1080 }
    };

    const audioConstraints = {
      deviceId: audioSource ? { exact: audioSource } : undefined,
      autoGainControl: false,
      echoCancellation: false,
      googAutoGainControl: false,
      noiseSuppression: false
    };

    try {
      if (videoStream) videoStream.getTracks().forEach(t => t.stop());
      if (audioStream) audioStream.getTracks().forEach(t => t.stop());

      videoStream = await navigator.mediaDevices.getUserMedia({ video: videoConstraints });
      audioStream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints });

      video.srcObject = videoStream;
      audio.srcObject = audioStream;

      video.onloadedmetadata = () => {
        video.play();
        menu.style.display = 'none';
        initWebGL();
        startRenderLoop();
      };
    } catch (err) {
      alert("Error starting media: " + err.message);
      console.error(err);
    }
  }

  function initWebGL() {
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;

    gl = canvas.getContext('webgl');
    if (!gl) {
      alert('WebGL not supported');
      return;
    }

    program = createProgram(gl, vsSource, fsSource);
    gl.useProgram(program);

    const positionLocation = gl.getAttribLocation(program, "a_position");
    const texCoordLocation = gl.getAttribLocation(program, "a_texCoord");

    positionBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    setPositionFullScreen();

    gl.enableVertexAttribArray(positionLocation);
    gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

    texCoordBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
      0, 0,
      1, 0,
      0, 1,
      0, 1,
      1, 0,
      1, 1,
    ]), gl.STATIC_DRAW);

    gl.enableVertexAttribArray(texCoordLocation);
    gl.vertexAttribPointer(texCoordLocation, 2, gl.FLOAT, false, 0, 0);

    texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);

    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

    videoAspect = video.videoWidth / video.videoHeight;

    window.addEventListener('resize', () => {
      canvas.width = window.innerWidth;
      canvas.height = window.innerHeight;
      updatePositionsForAspectRatio();
    });

    updatePositionsForAspectRatio();
  }

  function setPositionFullScreen() {
    const fullScreenCoords = new Float32Array([
      -1,  1,
       1,  1,
      -1, -1,
      -1, -1,
       1,  1,
       1, -1,
    ]);
    gl.bufferData(gl.ARRAY_BUFFER, fullScreenCoords, gl.STATIC_DRAW);
  }

  function updatePositionsForAspectRatio() {
    if (!gl) return;

    const canvasRatio = canvas.width / canvas.height;

    let drawWidth, drawHeight;

    if (canvasRatio > videoAspect) {
      drawHeight = 2;
      drawWidth = 2 * videoAspect / canvasRatio;
    } else {
      drawWidth = 2;
      drawHeight = 2 * canvasRatio / videoAspect;
    }

    const x1 = -drawWidth / 2;
    const x2 = drawWidth / 2;
    const y1 = drawHeight / 2;
    const y2 = -drawHeight / 2;

    const positions = new Float32Array([
      x1, y1,
      x2, y1,
      x1, y2,
      x1, y2,
      x2, y1,
      x2, y2,
    ]);

    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);
  }

  function startRenderLoop() {
    function render(now) {
      if (video.readyState >= 2) { // HAVE_CURRENT_DATA
        gl.viewport(0, 0, canvas.width, canvas.height);

        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texImage2D(
          gl.TEXTURE_2D,
          0,
          gl.RGBA,
          gl.RGBA,
          gl.UNSIGNED_BYTE,
          video
        );

        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);

        gl.drawArrays(gl.TRIANGLES, 0, 6);

        frames++;
        const nowMs = performance.now();
        if (nowMs - lastTime >= 1000) {
          fpsDisplay.textContent = `FPS: ${frames}`;
          frames = 0;
          lastTime = nowMs;
        }
      }

      requestAnimationFrame(render);
    }

    requestAnimationFrame(render);
  }

  startBtn.onclick = () => {
    startStream();
  };

  requestPermissionsAndListDevices();
</script>

</body>
</html>
